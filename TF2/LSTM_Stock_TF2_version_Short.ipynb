{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Stock TF2 version_Short.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a0KPOPJtu_S"
      },
      "source": [
        "# New York Stock Exchange stock price prediction using LSTM (Tensorflow 2)\n",
        "\n",
        "\n",
        "![tf2](https://miro.medium.com/max/1000/1*RGSPW8Zfs4W70SYrIu3xFA.png)\n",
        "\n",
        "Use S&P 500 companies historical prices to predict future prices\n",
        "\n",
        "![alt text](https://farm4.staticflickr.com/3835/14313202637_0cc6ec8649_z_d.jpg)\n",
        "\n",
        "Reference:https://www.kaggle.com/dgawlik/nyse/home\n",
        "\n",
        "This dataset is a playground for fundamental and technical analysis. It is said that 30% of traffic on stocks is already generated by machines, can trading be fully automated? If not, there is still a lot to learn from historical data.\n",
        "\n",
        "Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Iv2AY56Swn",
        "outputId": "dcbc08ca-c268-4131-b8d3-93b89f93fc06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/davidjohnnn/econ/master/prices-split-adjusted.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 10:39:07--  https://raw.githubusercontent.com/davidjohnnn/econ/master/prices-split-adjusted.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52701226 (50M) [text/plain]\n",
            "Saving to: ‘prices-split-adjusted.csv’\n",
            "\n",
            "prices-split-adjust 100%[===================>]  50.26M  79.1MB/s    in 0.6s    \n",
            "\n",
            "2020-11-17 10:39:12 (79.1 MB/s) - ‘prices-split-adjusted.csv’ saved [52701226/52701226]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swp7Xt75Vte8",
        "outputId": "87455c7f-ed95-4a33-d916-aec3c1e03596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prices-split-adjusted.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLGv7PEHN0Ig"
      },
      "source": [
        "# Setup\n",
        "import libraries needed for this application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBvORAQ27MGF"
      },
      "source": [
        "datapath = 'prices-split-adjusted.csv' #or locate in google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqjL7z3eH75v"
      },
      "source": [
        "#import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import itertools\n",
        "from sklearn import preprocessing\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers \\\n",
        "    import Dense, Embedding, LSTM, GRU, TimeDistributed, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12I7q96ySLac"
      },
      "source": [
        "# Read data\n",
        "\n",
        "![alt text](https://cdn.pixabay.com/photo/2017/09/01/05/49/reading-2703163_1280.jpg)\n",
        "\n",
        "#### Let's read the CSV file and find out what does it look like?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxhQMsx8TiwQ"
      },
      "source": [
        "The first 5 rows of this dataset contains the value of WLTM  during 5 Jan 2016 - 11 Jan 2016.  It contains stock prices of other companies in NYSE as well.\n",
        "\n",
        "WLTW - Willis Towers Watson is a global multinational risk management, insurance brokerage and advisory company. The firm has roots dating to 1828 and is the third largest insurance broker in the world.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfmwq_PnH75z",
        "outputId": "b5618785-9271-4200-db2a-f883591ebbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# datapath =\"/content/stock/prices-split-adjusted.csv\"\n",
        "df = pd.read_csv(datapath, index_col = 0)\n",
        "df[\"mv close\"] = df.close\n",
        "df.drop(['volume','close'], 1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>125.839996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>119.980003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>114.949997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>116.620003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-11</th>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>114.970001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           symbol        open         low        high    mv close\n",
              "date                                                             \n",
              "2016-01-05   WLTW  123.430000  122.309998  126.250000  125.839996\n",
              "2016-01-06   WLTW  125.239998  119.940002  125.540001  119.980003\n",
              "2016-01-07   WLTW  116.379997  114.930000  119.739998  114.949997\n",
              "2016-01-08   WLTW  115.480003  113.500000  117.440002  116.620003\n",
              "2016-01-11   WLTW  117.010002  114.089996  117.330002  114.970001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KInBtx_AUfvt"
      },
      "source": [
        "### Statistical Summary of this dataset\n",
        "\n",
        "*   count = number of rows in the dataset\n",
        "*   mean  = average opening/low/high/closing  price\n",
        "*   std = standard deviation\n",
        "*   min = min. opening/low/high/closing  price\n",
        "*   price at 25%/50%/75% percentile\n",
        "*   max = max. opening/low/high/closing  price\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV-xZLaySgEe",
        "outputId": "cfa41e96-5e71-4486-d7e9-f2e2337d3873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "      <td>851264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>64.993618</td>\n",
              "      <td>64.336541</td>\n",
              "      <td>65.639748</td>\n",
              "      <td>65.011913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>75.203893</td>\n",
              "      <td>74.459518</td>\n",
              "      <td>75.906861</td>\n",
              "      <td>75.201216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.660000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>1.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>31.270000</td>\n",
              "      <td>30.940001</td>\n",
              "      <td>31.620001</td>\n",
              "      <td>31.292776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>48.459999</td>\n",
              "      <td>47.970001</td>\n",
              "      <td>48.959999</td>\n",
              "      <td>48.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>75.120003</td>\n",
              "      <td>74.400002</td>\n",
              "      <td>75.849998</td>\n",
              "      <td>75.139999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1584.439941</td>\n",
              "      <td>1549.939941</td>\n",
              "      <td>1600.930054</td>\n",
              "      <td>1578.130005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                open            low           high       mv close\n",
              "count  851264.000000  851264.000000  851264.000000  851264.000000\n",
              "mean       64.993618      64.336541      65.639748      65.011913\n",
              "std        75.203893      74.459518      75.906861      75.201216\n",
              "min         1.660000       1.500000       1.810000       1.590000\n",
              "25%        31.270000      30.940001      31.620001      31.292776\n",
              "50%        48.459999      47.970001      48.959999      48.480000\n",
              "75%        75.120003      74.400002      75.849998      75.139999\n",
              "max      1584.439941    1549.939941    1600.930054    1578.130005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUPSU9PAXZxg"
      },
      "source": [
        "There are over 500 companies in this dataset including  Google, IBM, CBS Corporation, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv7HzTGLH754",
        "outputId": "c26f61ec-541f-4f6f-a1fa-d991fa645c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Symbol dimension\n",
        "symbols = list(set(df.symbol))\n",
        "print(\"Here are the list of companies in NYSE\")\n",
        "print(sorted(symbols))\n",
        "print(\"There are \" + str(len(symbols)) + \" companies in NYSE\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the list of companies in NYSE\n",
            "['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADS', 'ADSK', 'AEE', 'AEP', 'AES', 'AET', 'AFL', 'AGN', 'AIG', 'AIV', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALK', 'ALL', 'ALLE', 'ALXN', 'AMAT', 'AME', 'AMG', 'AMGN', 'AMP', 'AMT', 'AMZN', 'AN', 'ANTM', 'AON', 'APA', 'APC', 'APD', 'APH', 'ARNC', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXP', 'AYI', 'AZO', 'BA', 'BAC', 'BAX', 'BBBY', 'BBT', 'BBY', 'BCR', 'BDX', 'BEN', 'BHI', 'BIIB', 'BK', 'BLK', 'BLL', 'BMY', 'BSX', 'BWA', 'BXP', 'C', 'CA', 'CAG', 'CAH', 'CAT', 'CB', 'CBG', 'CBS', 'CCI', 'CCL', 'CELG', 'CERN', 'CF', 'CFG', 'CHD', 'CHK', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COG', 'COH', 'COL', 'COO', 'COP', 'COST', 'COTY', 'CPB', 'CRM', 'CSCO', 'CSRA', 'CSX', 'CTAS', 'CTL', 'CTSH', 'CTXS', 'CVS', 'CVX', 'CXO', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DISCA', 'DISCK', 'DLPH', 'DLR', 'DLTR', 'DNB', 'DOV', 'DOW', 'DPS', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'ENDP', 'EOG', 'EQIX', 'EQR', 'EQT', 'ES', 'ESRX', 'ESS', 'ETFC', 'ETN', 'ETR', 'EVHC', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FAST', 'FB', 'FBHS', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB', 'FL', 'FLIR', 'FLR', 'FLS', 'FMC', 'FOX', 'FOXA', 'FRT', 'FSLR', 'FTI', 'FTR', 'FTV', 'GD', 'GE', 'GGP', 'GILD', 'GIS', 'GLW', 'GM', 'GOOG', 'GOOGL', 'GPC', 'GPN', 'GPS', 'GRMN', 'GS', 'GT', 'GWW', 'HAL', 'HAR', 'HAS', 'HBAN', 'HBI', 'HCA', 'HCN', 'HCP', 'HD', 'HES', 'HIG', 'HOG', 'HOLX', 'HON', 'HP', 'HPE', 'HPQ', 'HRB', 'HRL', 'HRS', 'HSIC', 'HST', 'HSY', 'HUM', 'IBM', 'ICE', 'IDXX', 'IFF', 'ILMN', 'INTC', 'INTU', 'IP', 'IPG', 'IR', 'IRM', 'ISRG', 'ITW', 'IVZ', 'JBHT', 'JCI', 'JEC', 'JNJ', 'JNPR', 'JPM', 'JWN', 'K', 'KEY', 'KHC', 'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KORS', 'KR', 'KSS', 'KSU', 'L', 'LB', 'LEG', 'LEN', 'LH', 'LKQ', 'LLL', 'LLTC', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUK', 'LUV', 'LVLT', 'LYB', 'M', 'MA', 'MAA', 'MAC', 'MAR', 'MAS', 'MAT', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MHK', 'MJN', 'MKC', 'MLM', 'MMC', 'MMM', 'MNK', 'MNST', 'MO', 'MON', 'MOS', 'MPC', 'MRK', 'MRO', 'MSFT', 'MSI', 'MTB', 'MTD', 'MU', 'MUR', 'MYL', 'NAVI', 'NBL', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NFX', 'NI', 'NKE', 'NLSN', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NWL', 'NWS', 'NWSA', 'O', 'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYX', 'PBCT', 'PBI', 'PCAR', 'PCG', 'PCLN', 'PDCO', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PX', 'PXD', 'PYPL', 'QCOM', 'QRVO', 'R', 'RAI', 'RCL', 'REGN', 'RF', 'RHI', 'RHT', 'RIG', 'RL', 'ROK', 'ROP', 'ROST', 'RRC', 'RSG', 'RTN', 'SBUX', 'SCG', 'SCHW', 'SE', 'SEE', 'SHW', 'SIG', 'SJM', 'SLB', 'SLG', 'SNA', 'SNI', 'SO', 'SPG', 'SPGI', 'SPLS', 'SRCL', 'SRE', 'STI', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SWN', 'SYF', 'SYK', 'SYMC', 'SYY', 'T', 'TAP', 'TDC', 'TDG', 'TEL', 'TGNA', 'TGT', 'TIF', 'TJX', 'TMK', 'TMO', 'TRIP', 'TROW', 'TRV', 'TSCO', 'TSN', 'TSO', 'TSS', 'TWX', 'TXN', 'TXT', 'UAA', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNH', 'UNM', 'UNP', 'UPS', 'URBN', 'URI', 'USB', 'UTX', 'V', 'VAR', 'VFC', 'VIAB', 'VLO', 'VMC', 'VNO', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VZ', 'WAT', 'WBA', 'WDC', 'WEC', 'WFC', 'WFM', 'WHR', 'WLTW', 'WM', 'WMB', 'WMT', 'WRK', 'WU', 'WY', 'WYN', 'WYNN', 'XEC', 'XEL', 'XL', 'XLNX', 'XOM', 'XRAY', 'XRX', 'XYL', 'YHOO', 'YUM', 'ZBH', 'ZION', 'ZTS']\n",
            "There are 501 companies in NYSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvKb4PKQX6sE"
      },
      "source": [
        "# Let's predict Google's stock price!\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/4/4a/Logo_2013_Google.png)\n",
        "* you can also replace \"GOOG\" with any company of your choice!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_XSkIvBH756",
        "outputId": "ff9e7690-5994-4dc2-9e27-9de70bf99e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#Focus only 1 stock :GOOG\n",
        "SYM = 'GOOG'\n",
        "df = df[df.symbol == SYM]\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>312.304948</td>\n",
              "      <td>310.955001</td>\n",
              "      <td>313.580158</td>\n",
              "      <td>312.205308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>312.419511</td>\n",
              "      <td>309.610028</td>\n",
              "      <td>312.748278</td>\n",
              "      <td>310.830459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>311.761979</td>\n",
              "      <td>302.048370</td>\n",
              "      <td>311.761979</td>\n",
              "      <td>302.994813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>303.562685</td>\n",
              "      <td>295.218951</td>\n",
              "      <td>303.861575</td>\n",
              "      <td>295.941242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>294.895159</td>\n",
              "      <td>293.455551</td>\n",
              "      <td>300.499172</td>\n",
              "      <td>299.886470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  open         low        high    mv close\n",
              "date                                                      \n",
              "2010-01-04  312.304948  310.955001  313.580158  312.205308\n",
              "2010-01-05  312.419511  309.610028  312.748278  310.830459\n",
              "2010-01-06  311.761979  302.048370  311.761979  302.994813\n",
              "2010-01-07  303.562685  295.218951  303.861575  295.941242\n",
              "2010-01-08  294.895159  293.455551  300.499172  299.886470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj8eRV09TlXx",
        "outputId": "41039747-2ba5-41af-dfdb-b7626abd8a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#Statistical Summary\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "      <td>1762.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>459.806530</td>\n",
              "      <td>455.659218</td>\n",
              "      <td>463.484281</td>\n",
              "      <td>459.617409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>174.026396</td>\n",
              "      <td>172.601608</td>\n",
              "      <td>175.232816</td>\n",
              "      <td>173.946191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>218.336998</td>\n",
              "      <td>216.005726</td>\n",
              "      <td>220.314587</td>\n",
              "      <td>217.221182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>298.255074</td>\n",
              "      <td>295.896412</td>\n",
              "      <td>300.824200</td>\n",
              "      <td>298.389573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>436.554429</td>\n",
              "      <td>434.103619</td>\n",
              "      <td>438.701390</td>\n",
              "      <td>436.711351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>578.422067</td>\n",
              "      <td>572.884750</td>\n",
              "      <td>581.870130</td>\n",
              "      <td>577.497020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>816.679993</td>\n",
              "      <td>805.140015</td>\n",
              "      <td>816.679993</td>\n",
              "      <td>813.109985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              open          low         high     mv close\n",
              "count  1762.000000  1762.000000  1762.000000  1762.000000\n",
              "mean    459.806530   455.659218   463.484281   459.617409\n",
              "std     174.026396   172.601608   175.232816   173.946191\n",
              "min     218.336998   216.005726   220.314587   217.221182\n",
              "25%     298.255074   295.896412   300.824200   298.389573\n",
              "50%     436.554429   434.103619   438.701390   436.711351\n",
              "75%     578.422067   572.884750   581.870130   577.497020\n",
              "max     816.679993   805.140015   816.679993   813.109985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI7xkq09UGY0",
        "outputId": "af8fa71d-28ca-4c50-fe07-a50f3d1c783f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Date data dimension\n",
        "import datetime \n",
        "\n",
        "print(df.index.min())\n",
        "print(df.index.max())\n",
        "delta = datetime.datetime.strptime(df.index.max(),'%Y-%m-%d')- datetime.datetime.strptime(df.index.min(),'%Y-%m-%d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-01-04\n",
            "2016-12-30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BdpodyJTete"
      },
      "source": [
        "# Normalize data\n",
        "Normalization is a common process in machine learning. We do it to make sure that all features are using a common scale. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BifdUT7zH75-",
        "outputId": "b676f0d1-ef05-4509-a822-81398ac020ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "def normalize_data(df): # nomalize stock data\n",
        "    min_max_scaler = preprocessing.MinMaxScaler() #min max scaler\n",
        "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
        "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
        "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
        "    df['mv close'] = min_max_scaler.fit_transform(df['mv close'].values.reshape(-1,1))\n",
        "    return df\n",
        "df = normalize_data(df)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>mv close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-01-04</th>\n",
              "      <td>0.157047</td>\n",
              "      <td>0.161167</td>\n",
              "      <td>0.156390</td>\n",
              "      <td>0.159399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-05</th>\n",
              "      <td>0.157238</td>\n",
              "      <td>0.158884</td>\n",
              "      <td>0.154995</td>\n",
              "      <td>0.157092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-06</th>\n",
              "      <td>0.156140</td>\n",
              "      <td>0.146049</td>\n",
              "      <td>0.153341</td>\n",
              "      <td>0.143942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-07</th>\n",
              "      <td>0.142436</td>\n",
              "      <td>0.134457</td>\n",
              "      <td>0.140094</td>\n",
              "      <td>0.132105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-08</th>\n",
              "      <td>0.127950</td>\n",
              "      <td>0.131464</td>\n",
              "      <td>0.134455</td>\n",
              "      <td>0.138726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-11</th>\n",
              "      <td>0.138324</td>\n",
              "      <td>0.135632</td>\n",
              "      <td>0.135466</td>\n",
              "      <td>0.137965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-12</th>\n",
              "      <td>0.132654</td>\n",
              "      <td>0.130525</td>\n",
              "      <td>0.130204</td>\n",
              "      <td>0.129079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-13</th>\n",
              "      <td>0.115038</td>\n",
              "      <td>0.118603</td>\n",
              "      <td>0.122035</td>\n",
              "      <td>0.126245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-14</th>\n",
              "      <td>0.121207</td>\n",
              "      <td>0.126137</td>\n",
              "      <td>0.126896</td>\n",
              "      <td>0.128552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-01-15</th>\n",
              "      <td>0.129066</td>\n",
              "      <td>0.122104</td>\n",
              "      <td>0.126362</td>\n",
              "      <td>0.120318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                open       low      high  mv close\n",
              "date                                              \n",
              "2010-01-04  0.157047  0.161167  0.156390  0.159399\n",
              "2010-01-05  0.157238  0.158884  0.154995  0.157092\n",
              "2010-01-06  0.156140  0.146049  0.153341  0.143942\n",
              "2010-01-07  0.142436  0.134457  0.140094  0.132105\n",
              "2010-01-08  0.127950  0.131464  0.134455  0.138726\n",
              "2010-01-11  0.138324  0.135632  0.135466  0.137965\n",
              "2010-01-12  0.132654  0.130525  0.130204  0.129079\n",
              "2010-01-13  0.115038  0.118603  0.122035  0.126245\n",
              "2010-01-14  0.121207  0.126137  0.126896  0.128552\n",
              "2010-01-15  0.129066  0.122104  0.126362  0.120318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmZ10qsCUV7"
      },
      "source": [
        "# Generate Data for LSTM\n",
        "![alt text](https://drive.google.com/uc?id=1SOT-t7z2qbfhzJnGmWMhJpz8JlB5V1kn)\n",
        "\n",
        "Predict the stock price based on the data from the previous 5 days"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3-hcDDBH76D"
      },
      "source": [
        "def load_data(stock, seq_len):   \n",
        "    n_features = len(stock.columns) #count columns of stock df 4 features open/low/high/close\n",
        "    data = stock.to_numpy()  #change to matrix numpy array\n",
        "    sequence_length = seq_len + 1 #5+1\n",
        "    result = []\n",
        "    \n",
        "    for index in range(len(data) - sequence_length): #1762 data but exclude sequence len , 0 to 1762-6 => 1756\n",
        "        result.append(data[index: index + sequence_length]) # construct table with 1756 2d arrays, each with [6,nfeature] (1756,6,4)\n",
        "    \n",
        "    result = np.array(result)\n",
        "    row = round(0.9 * result.shape[0]) # 90% of 1756 data\n",
        "    train = result[:int(row), :] # select first 90% as train data = 1580 data\n",
        "\n",
        "    x_train = train[:, :-1] #(1580,5,4) , x is previous 5 days data with 4 columns\n",
        "    y_train = train[:, -1][:,-1] #(1580), y is the close price of the sixth days\n",
        "    \n",
        "    x_test = result[int(row):, :-1]  # test is remaining rows 10% of data (176,5,4)\n",
        "    y_test = result[int(row):, -1][:,-1] #(176,)\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_features)) # reshape again (1580,5,4)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], n_features))  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0WnWP65H76H",
        "outputId": "b6d21b38-aa59-48dd-8e92-31f06c186d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# set feature dimension and look back period\n",
        "n_features = 4\n",
        "prev_days = 5\n",
        "X_train, y_train, X_test, y_test = load_data(df, prev_days)\n",
        "print(X_train[0], y_train[0])\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15704696 0.16116746 0.15638998 0.15939908]\n",
            " [0.15723843 0.15888449 0.15499506 0.15709185]\n",
            " [0.15613951 0.14604929 0.15334121 0.14394234]\n",
            " [0.14243617 0.13445699 0.14009362 0.13210528]\n",
            " [0.12795029 0.13146379 0.13445546 0.13872603]] 0.1379653023031744\n",
            "(1580, 5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq58-J-ECbEh"
      },
      "source": [
        "# Build LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSOFqQcd3q_g"
      },
      "source": [
        "**References **\n",
        "\n",
        "Return sequence:\n",
        "\n",
        "https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n",
        "https://stackoverflow.com/questions/42755820/how-to-use-return-sequences-option-and-timedistributed-layer-in-keras\n",
        "\n",
        "Reshape input for lstm\n",
        "\n",
        "https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
        "\n",
        "\n",
        "Stack LSTM\n",
        "\n",
        " https://machinelearningmastery.com/stacked-long-short-term-memory-networks/\n",
        " http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        " \n",
        "![](https://drive.google.com/uc?id=123aJD6phLzahdkhntLG2JL0A4IjCakDl)\n",
        " ![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/architecture_stacked_lstm.png)\n",
        " ![](http://adventuresinmachinelearning.com/wp-content/uploads/2018/01/Keras-LSTM-return-sequences-diagram-1024x275.png)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOUwcTJxH76N"
      },
      "source": [
        "def build_model(layers):\n",
        "    p = 0.2 #drop out 20%\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True)) # 5 previous days ,4 features\n",
        "    model.add(Dropout(p)) # dropout between layer\n",
        "\n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dropout(p))\n",
        "\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    model.add(Dense(layers[2],activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse',optimizer='adam', metrics=['mse'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model([n_features, prev_days, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiNdO5cLCeZl"
      },
      "source": [
        "# Train LSTM model\n",
        "\n",
        "This is where your model learn from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3p7Q_CqH76R",
        "outputId": "78273120-b307-4231-8cf7-0e6fa632e875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#setseed to produce same result\n",
        "from numpy.random import seed\n",
        "seed(5)\n",
        "\n",
        "tf.random.set_seed(1992)\n",
        "\n",
        "# Checkpoint for call back function\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"/content/weights.best.hdf5\" #for print only best model\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "#validation split select 10% of data to validate (last 10% sequence)\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_split=0.1, verbose=1, callbacks =callbacks_list) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 0.0108 - mse: 0.0108\n",
            "Epoch 00001: val_loss improved from inf to 0.00187, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 1s 19ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 2/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 7.9794e-04 - mse: 7.9794e-04\n",
            "Epoch 00002: val_loss did not improve from 0.00187\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.7417e-04 - mse: 7.7417e-04 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 3/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 6.8015e-04 - mse: 6.8015e-04\n",
            "Epoch 00003: val_loss improved from 0.00187 to 0.00120, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.6320e-04 - mse: 6.6320e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 4/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 7.3646e-04 - mse: 7.3646e-04\n",
            "Epoch 00004: val_loss did not improve from 0.00120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.8944e-04 - mse: 6.8944e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 5/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 6.9805e-04 - mse: 6.9805e-04\n",
            "Epoch 00005: val_loss improved from 0.00120 to 0.00103, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.0665e-04 - mse: 7.0665e-04 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 6/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 5.5744e-04 - mse: 5.5744e-04\n",
            "Epoch 00006: val_loss did not improve from 0.00103\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.3618e-04 - mse: 5.3618e-04 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 7/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 6.5702e-04 - mse: 6.5702e-04\n",
            "Epoch 00007: val_loss did not improve from 0.00103\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.7681e-04 - mse: 6.7681e-04 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 8/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 9.1755e-04 - mse: 9.1755e-04\n",
            "Epoch 00008: val_loss did not improve from 0.00103\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.2820e-04 - mse: 8.2820e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 9/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 6.1787e-04 - mse: 6.1787e-04\n",
            "Epoch 00009: val_loss did not improve from 0.00103\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.8331e-04 - mse: 5.8331e-04 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 10/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 5.6576e-04 - mse: 5.6576e-04\n",
            "Epoch 00010: val_loss improved from 0.00103 to 0.00089, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 5.6682e-04 - mse: 5.6682e-04 - val_loss: 8.8951e-04 - val_mse: 8.8951e-04\n",
            "Epoch 11/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 5.3818e-04 - mse: 5.3818e-04\n",
            "Epoch 00011: val_loss did not improve from 0.00089\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.6439e-04 - mse: 5.6439e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 12/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 5.8127e-04 - mse: 5.8127e-04\n",
            "Epoch 00012: val_loss did not improve from 0.00089\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.9264e-04 - mse: 5.9264e-04 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 13/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 6.1743e-04 - mse: 6.1743e-04\n",
            "Epoch 00013: val_loss improved from 0.00089 to 0.00075, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 5.8808e-04 - mse: 5.8808e-04 - val_loss: 7.4644e-04 - val_mse: 7.4644e-04\n",
            "Epoch 14/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 5.4906e-04 - mse: 5.4906e-04\n",
            "Epoch 00014: val_loss did not improve from 0.00075\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.2193e-04 - mse: 5.2193e-04 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 15/20\n",
            "36/45 [=======================>......] - ETA: 0s - loss: 4.7698e-04 - mse: 4.7698e-04\n",
            "Epoch 00015: val_loss did not improve from 0.00075\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.9205e-04 - mse: 4.9205e-04 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 16/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 5.6710e-04 - mse: 5.6710e-04\n",
            "Epoch 00016: val_loss did not improve from 0.00075\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.4814e-04 - mse: 5.4814e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 17/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 7.2723e-04 - mse: 7.2723e-04\n",
            "Epoch 00017: val_loss improved from 0.00075 to 0.00072, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.7253e-04 - mse: 6.7253e-04 - val_loss: 7.2474e-04 - val_mse: 7.2474e-04\n",
            "Epoch 18/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 5.6678e-04 - mse: 5.6678e-04\n",
            "Epoch 00018: val_loss improved from 0.00072 to 0.00071, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 5.6228e-04 - mse: 5.6228e-04 - val_loss: 7.0535e-04 - val_mse: 7.0535e-04\n",
            "Epoch 19/20\n",
            "35/45 [======================>.......] - ETA: 0s - loss: 5.2103e-04 - mse: 5.2103e-04\n",
            "Epoch 00019: val_loss did not improve from 0.00071\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.0735e-04 - mse: 5.0735e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 20/20\n",
            "37/45 [=======================>......] - ETA: 0s - loss: 5.4001e-04 - mse: 5.4001e-04\n",
            "Epoch 00020: val_loss improved from 0.00071 to 0.00070, saving model to /content/weights.best.hdf5\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.0078e-04 - mse: 6.0078e-04 - val_loss: 6.9552e-04 - val_mse: 6.9552e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9hRBQRhxzsI"
      },
      "source": [
        "#Load best model from check point\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mIHWQyTxzOW",
        "outputId": "fa09a7b7-3166-42be-e4ff-56c0ca98e41a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load weights\n",
        "print(filepath)\n",
        "model.load_weights(filepath)\n",
        "\n",
        "# # Compile model (required to make predictions)\n",
        "# model.compile(loss='mse',optimizer='adam', metrics=['mse'])\n",
        "# print(\"Created model and loaded weights from file\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/weights.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtmzADYzxyml"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISoe_EGYxxZf"
      },
      "source": [
        "diff=[]\n",
        "predict = model.predict(X_test)\n",
        "for d in range(len(y_test)):\n",
        "    pred = predict[d][0]\n",
        "    diff.append(abs(y_test[d] - pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6giLzdAxwmZ",
        "outputId": "52a9f481-4e64-43ef-9671-3ee4afb67e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(predict.shape)\n",
        "print(diff[0])\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176, 1)\n",
            "0.011583537192335291\n",
            "(176, 5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR98buG_E_oM"
      },
      "source": [
        "# Denomalize prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJUDVokCH76Y",
        "outputId": "cc3dc1ec-a09e-4ae2-9f69-0047c3683a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "df = pd.read_csv(datapath, index_col = 0)\n",
        "df[\"mv close\"] = df.close\n",
        "df.drop(['volume', 'close'], 1, inplace=True)\n",
        "df = df[df.symbol == SYM]\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "\n",
        "def denormalize(df, normalized_value): #\n",
        "    df = df['mv close'].values.reshape(-1,1)\n",
        "    normalized_value = normalized_value.reshape(-1,1)\n",
        "\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    _ = min_max_scaler.fit_transform(df)\n",
        "    denorm = min_max_scaler.inverse_transform(normalized_value)\n",
        "    return denorm\n",
        "\n",
        "new_pred = denormalize(df, predict)\n",
        "newy_test = denormalize(df, y_test)\n",
        "\n",
        "print( sqrt( mean_squared_error(newy_test, new_pred) ) )\n",
        "print( np.mean(newy_test) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.882268506579871\n",
            "752.340568215909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8sEDlcONaO"
      },
      "source": [
        "# Final prediction performance with simulate trading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdYS3W4sH76o",
        "outputId": "657562ac-fad5-409f-d2cc-655438a6ffb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(new_pred,color='red', label='Prediction')\n",
        "plt.plot(newy_test,color='blue', label='Actual')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or_GhyujTejR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}